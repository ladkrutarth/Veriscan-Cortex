# Veriscan â€” Advanced Fraud Detection & Private AI Intelligence Dashboard

> **Course:** CS 5588 â€” Data Science Capstone | **Date:** February 2026

---

## ğŸ“‹ Table of Contents
- [Project Overview](#project-overview)
- [AI Accuracy Scorecard](#ai-accuracy-scorecard)
- [System Architecture](#system-architecture)
- [Visual Architecture](#visual-architecture)
- [Local AI Intelligence](#local-ai-intelligence)
- [Pipeline Workflow](#pipeline-workflow)
- [Repository Structure](#repository-structure)
- [Quick Start](#quick-start)

---

## Project Overview

Veriscan is an end-to-end **Fraud Detection & Security Platform** that processes transaction data through a multi-stage intelligence pipeline:

**Data Ingestion â†’ Feature Engineering â†’ Hybrid Fraud Modeling â†’ Secure Identity Auth â†’ Private Agentic AI**

### ğŸ›¡ï¸ What is Veriscan?
The name **Veriscan** represents the fusion of two core security principles:
- **VERI** (*Verification & Veracity*): A commitment to absolute identity truth through dynamic authentication and data-backed evidence.
- **SCAN** (*Scanning & Surveillance*): The power of autonomous agentic "scans" that explore transaction history, risk profiles, and global trends to detect threats in milliseconds.

\

## Visual Architecture

### ğŸ§  Private AI Cortex (Agentic AI)
The **GuardAgent** leverages a local Llama-3 model for autonomous investigations, using a **Hybrid Intent Router** to choose between deterministic keyword matching and deep LLM reasoning.

```mermaid
graph TD
    User([User Request]) --> Router{Hybrid Router}
    Router -->|Match| Tool[Direct Tool Call]
    Router -->|Fallback| Brain{Llama-3 Reasoning}
    Brain -->|Step-by-Step| Tool
    Tool -->|Query DB| SQL[(Financial Records)]
    Tool -->|Risk Analysis| ML[98% Fraud Model]
    Tool -->|Semantic Search| RAG[Vector Memory]
    SQL --> Results[Observation]
    ML --> Results
    RAG --> Results
    Results -->|Final Analysis| Final[Consolidated Report]
    Final --> User
```

### ğŸ” Local RAG Architecture
The RAG system enables semantic retrieval over 1,300+ local documents (Kaggle transactions + CFPB complaints) without sending data to external APIs.

```mermaid
graph LR
    subgraph Ingestion [Data Ingestion]
        TXN[(Transactions)]
        CFPB[(CFPB Complaints)]
    end

    subgraph VectorDB [Semantic Memory]
        Embed[all-MiniLM-L6-v2]
        Chroma[(ChromaDB)]
    end

    subgraph Retrieval [Augmented Generation]
        Query([User Query])
        Search{Vector Search}
        Context[Fused Context]
        LLM[Llama-3 Reasoning]
    end

    TXN --> Embed
    CFPB --> Embed
    Embed --> Chroma
    Query --> Search
    Chroma --> Search
    Search --> Context
    Context --> LLM
    LLM --> Answer([Final Response])
```

### ğŸ›¡ï¸ Hybrid Fraud Intelligence (ML + Heuristics)
The scoring engine combines 19 statistical "Heuristic Signals" with a supervised **Random Forest Classifier** to learn non-linear fraud signatures.

```mermaid
graph LR
    subgraph Data [Data Ingestion]
        TXN[(Transactions)]
    end

    subgraph FE [Layer 1: Heuristics & FE]
        HEU{19 Signals}
        HEU --> Z[Amount Z-Score]
        HEU --> V[Velocity 1h/24h/7d]
        HEU --> E[Location Entropy]
        HEU --> R[Category Risk]
    end

    subgraph ML [Layer 2: Core ML]
        RF[[Random Forest: 98.18% Acc]]
    end

    subgraph Output [Risk Scoring]
        SCORE{Final Risk Score}
    end

    TXN --> HEU
    Z --> RF
    V --> RF
    E --> RF
    R --> RF
    RF --> SCORE
    Z -.->|Override| SCORE
    E -.->|Override| SCORE
```

---

## Local AI Intelligence

Veriscan features a cutting-edge, local-first AI stack designed for maximum data privacy and performance on Mac hardware.

- **LLM**: `Meta-Llama-3-8B-Instruct` (4-bit quantized).
- **Inference**: **MLX-LM** (Native GPU acceleration for M1/M2/M3 chips).
- **Embeddings**: `all-MiniLM-L6-v2` (Local execution via `sentence-transformers`).
- **Vector Database**: **ChromaDB** (Persistent local storage for RAG context).

---

## Repository Structure

```
Veriscan-Dashboard/
â”œâ”€â”€ streamlit_app.py                    # Main 5-Tab Dashboard UI
â”œâ”€â”€ Phase-2-Report.md                   # Phase 2 Submission Report
â”œâ”€â”€ CONTRIBUTIONS.md                    # Team Contribution Breakdown
â”œâ”€â”€ requirements.txt                    # Python Dependencies
â”‚
â”œâ”€â”€ models/                             # Intelligence & Modeling Layer
â”‚   â”œâ”€â”€ local_llm.py                    # ğŸ§  MLX-LM Wrapper (Llama-3)
â”‚   â”œâ”€â”€ guard_agent_local.py            # ğŸ¤– Hybrid GuardAgent (100% Accuracy)
â”‚   â”œâ”€â”€ rag_engine_local.py             # ğŸ” Local RAG & Vector Store
â”‚   â”œâ”€â”€ train_fraud_model.py            # ğŸš¨ ML Training (RF 98%)
â”‚   â”œâ”€â”€ habit_model.py                  # ğŸ‘¤ User Behavior Profiling
â”‚   â””â”€â”€ compare_ml_models.py            # ğŸ“Š Accuracy Benchmarking Suite
â”‚
â”œâ”€â”€ scripts/                            # Data Pipeline
â”‚   â”œâ”€â”€ load_kaggle_data.py             # ğŸ“¦ Kaggle Data Adapter
â”‚   â”œâ”€â”€ feature_engineering.py          # âš™ï¸ 19 Health Signals
â”‚   â”œâ”€â”€ upload_all_to_snowflake.py      # â˜ï¸ Snowflake Batch Uploader
â”‚   â””â”€â”€ ingest_config.yaml              # ğŸ”§ Connection Config
â”‚
â”œâ”€â”€ sql/                                # Snowflake SQL Layer
â”‚   â”œâ”€â”€ create_tables.sql               # ğŸ“‹ DDL: 5 Tables + 2 Views
â”‚   â””â”€â”€ analytical_queries.sql          # ğŸ“Š 8 Analytical Queries
â”‚
â”œâ”€â”€ dataset/csv_data/                   # Data Store (Sampled for GitHub)
â”‚   â”œâ”€â”€ fraudTrain_sampled.csv          # Sampled Training Set
â”‚   â”œâ”€â”€ fraudTest_sampled.csv           # Sampled Test Set
â”‚   â”œâ”€â”€ cfpb_credit_card_sampled.csv    # Sampled CFPB Complaints
â”‚   â””â”€â”€ pipeline_logs.csv               # Pipeline Audit Trail
â”‚
â””â”€â”€ docs/
    â””â”€â”€ architecture_diagram.png        # System Architecture Diagram
```

---

## â˜ï¸ Snowflake Data Platform

Veriscan integrates with **Snowflake** for scalable analytics and data warehousing.

| Table | Purpose |
|-------|--------|
| `RAW_TRANSACTIONS` | Source transaction data |
| `TRANSACTION_FEATURES` | 19 engineered signals |
| `FRAUD_SCORES` | ML + heuristic risk scores |
| `AUTH_PROFILES` | User security profiles |
| `PIPELINE_RUNS` | Pipeline audit trail |

**Views:** `ENRICHED_TRANSACTIONS` (joined data), `USER_RISK_DASHBOARD` (aggregated risk)

See `sql/create_tables.sql` for schema DDL and `sql/analytical_queries.sql` for 8 production-ready queries.

---

## Quick Start

### 1. Requirements
- macOS with Apple Silicon (M1/M2/M3)
- Python 3.9+ (Anaconda environment recommended)

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Run the Data Pipeline
```bash
# Prepare dataset (requires fraudTrain.csv in dataset/csv_data/)
python scripts/load_kaggle_data.py --input dataset/csv_data/fraudTrain.csv

# Compute features
python scripts/feature_engineering.py

# Train the fraud model
python models/train_fraud_model.py

# (Optional) Upload to Snowflake
export SNOWFLAKE_ACCOUNT="your-account"
export SNOWFLAKE_USER="your-user"
export SNOWFLAKE_PASSWORD="your-password"
python scripts/upload_all_to_snowflake.py
```

### 4. Launch Dashboard
```bash
streamlit run streamlit_app.py
```
*Note: On first run, the Llama-3 model (~4.9GB) will be downloaded automatically.*

---

## ğŸ”„ Reproducibility & Deployment

| Aspect | Details |
|--------|--------|
| **Environment** | Python 3.9+, dependencies in `requirements.txt` |
| **Model Versioning** | `fraud_model_rf.joblib` + `encoders.joblib` (deterministic `random_state=42`) |
| **Dataset** | Kaggle `kartik2112/fraud-detection` (download separately) |
| **Vector Store** | ChromaDB (rebuilt on demand via `rag_engine_local.py`) |
| **Config** | `scripts/ingest_config.yaml` (supports env var overrides) |
| **Secrets** | All credentials via environment variables; `.env` in `.gitignore` |

---
**Status**: Private & Operational | **Accuracy**: 100% Agent / 98% ML | **Platform**: Apple Silicon Optimized
